{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Unsupervised_News_Aggregator_Training.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "authorship_tag": "ABX9TyMuLSYRSi8BLNg6t1iINu12",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "TPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/shashanknigade/Data-Science/blob/main/Unsupervised_News_Aggregator_Training.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "l7iOugaQ0o0h"
      },
      "source": [
        "# News Article Aggregator\n",
        "---\n",
        "### Problem Statement\n",
        "Develop algorithm technique to group news articles by story.\n",
        "**Dataset**:\n",
        "https://www.kaggle.com/uciml/news-aggregator-dataset\n",
        "\n",
        "---\n",
        "\n",
        "### Approach\n",
        "1.   Text Preprocessing using Gensim & NLTK Package\n",
        "1.   Doc2Vec generation\n",
        "1.   Dimensionality reduction using stacked autoencoders\n",
        "1.   Unsupervised clustering using kMeans algorithm\n",
        "1.   Metrics calculation\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mt0r6kO0ti7C",
        "outputId": "cc847ccb-632c-40e1-ea39-345a2b01c9a4"
      },
      "source": [
        "# Import all necessary libraries\n",
        "# For file copy from Kaggle etc.\n",
        "import os, shutil\n",
        "from google.colab import drive\n",
        "import zipfile\n",
        "# For data exploration and graphs\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "# For text preprocessing\n",
        "import gensim\n",
        "from gensim.parsing.preprocessing import remove_stopwords, preprocess_string\n",
        "from gensim.parsing.preprocessing import strip_punctuation\n",
        "from gensim.models.doc2vec import Doc2Vec, TaggedDocument\n",
        "import nltk\n",
        "from nltk.tokenize import word_tokenize\n",
        "# For saving models etc\n",
        "import pickle\n",
        "# Deep Neural Network libraries\n",
        "from tensorflow.keras.layers import Dense\n",
        "from tensorflow.keras.models import Sequential\n",
        "# KMeans\n",
        "from sklearn.cluster import KMeans,MiniBatchKMeans\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Ipd3isMB3efz"
      },
      "source": [
        "### Folder Structure Setup and input data\n",
        "`Google Drive` - \n",
        "  - `Kaggle`\n",
        "    - `kaggle.json` - `Contains username and API key for downloading data from Kaggle directly`\n",
        "\n",
        "`Colab Folder`\n",
        "  - `content`\n",
        "    - `data` - csv file downloaded here\n",
        "      - `kaggle` - `kaggle.json copied here`"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JZuV4AUW2yRq",
        "outputId": "1bc19fb1-c9d3-4183-d111-7d93c1d30962"
      },
      "source": [
        "# Mount the drive to read kaggle config file\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4xuLB974tpOy"
      },
      "source": [
        "# global config values\n",
        "zipName = 'news-aggregator-dataset.zip'\n",
        "csvFileName = 'uci-news-aggregator.csv'\n",
        "modelFileSaveLocation = '/content/gdrive/MyDrive'\n",
        "run = 'newsagg-1'\n",
        "exportModels = False"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CJMSSj9Otyky"
      },
      "source": [
        "# Create kaggle folder\n",
        "os.makedirs('data',exist_ok=True)\n",
        "os.makedirs('data/kaggle',exist_ok=True)\n",
        "# Change the current working directory to data where we will download \n",
        "# the data\n",
        "os.chdir(os.path.join(os.getcwd(),'data'))"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gl5NO67et2JP"
      },
      "source": [
        "# copy kaggle.json to the content folder's kaggle folder\n",
        "shutil.copy('/content/gdrive/MyDrive/kaggle/kaggle.json',\n",
        "            'kaggle')\n",
        "# Set environment for kaggle directory to the folder in prev. step\n",
        "os.environ['KAGGLE_CONFIG_DIR'] = 'kaggle'"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0ErZEoAQt6Lf",
        "outputId": "cc9ba10c-1e54-4205-83bb-545ba7c8ac85"
      },
      "source": [
        "# download the dataset\n",
        "!kaggle datasets download -d uciml/news-aggregator-dataset\n",
        "zipfileref = zipfile.ZipFile(zipName,'r')\n",
        "# Extract the files in pwd\n",
        "zipfileref.extractall()"
      ],
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "news-aggregator-dataset.zip: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GujEwXzA6F_w"
      },
      "source": [
        "### Text Preprocessing"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pQ9p4lSht-LR"
      },
      "source": [
        "# Read the csv file\n",
        "df = pd.read_csv(csvFileName)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSteAJ7suGzW"
      },
      "source": [
        "def ProcessTest(text):\n",
        "  '''\n",
        "    text: Input Text\n",
        "    This function removes stop words from a text, removes punctuation\n",
        "    and lowers the case\n",
        "  '''\n",
        "  text = remove_stopwords(text)\n",
        "  text = strip_punctuation(text)\n",
        "  return str.lower(str.strip(text))"
      ],
      "execution_count": 94,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "u834z7kKuIo7"
      },
      "source": [
        "# Store processed text in list\n",
        "processedText = []\n",
        "# Read and process TITLE column in the CSV which will be the input to\n",
        "# this algorithm\n",
        "for index, value in df['TITLE'].items():\n",
        "    processedText.append([index,ProcessTest(value)])\n"
      ],
      "execution_count": 95,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "RlifXS_xuOSf"
      },
      "source": [
        "# Create a tagged document object list by tokenizing the words in a sentence from processedText\n",
        "inputText = [TaggedDocument(word_tokenize(sen[1]),[sen[0]]) for sen in processedText]"
      ],
      "execution_count": 96,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jeZFVraSuQXA"
      },
      "source": [
        "# Generate a Doc2Vec from the input text of size 200\n",
        "#https://radimrehurek.com/gensim/models/doc2vec.html?highlight=doc2vec#module-gensim.models.doc2vec \n",
        "vec_size = 200\n",
        "gmodel = Doc2Vec(inputText, vector_size=vec_size, window=2, min_count=1, workers=4)"
      ],
      "execution_count": 97,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qq8gGYwRwhdW",
        "outputId": "616270a7-2154-4713-a939-779655bdcef4"
      },
      "source": [
        "gmodel.docvecs.vectors_docs.shape"
      ],
      "execution_count": 98,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(422419, 200)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 98
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VUWx0dZ5xpbD"
      },
      "source": [
        "# if the config value is set to export the model\n",
        "if exportModels:\n",
        "  # Export processed Text\n",
        "  folder = os.path.join(modelFileSaveLocation,run)\n",
        "  # Create folder if it does not exist\n",
        "  os.makedirs(folder,exist_ok=True)\n",
        "  gmodel.save(os.path.join(folder,'newsaggword2vec_200.pkl'))"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gdP6-cP8w4aL"
      },
      "source": [
        "# Load pre-trained Word2Vec model.\n",
        "gmodel = gensim.models.Doc2Vec.load(\"/content/gdrive/MyDrive/newsaggword2vec_200.pkl\")"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NuGurJedxibU"
      },
      "source": [
        "X = gmodel.docvecs.vectors_docs"
      ],
      "execution_count": 129,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "nudZEcGtCI4p"
      },
      "source": [
        "### Dimensionality Reduction\n",
        "*   Create AutoEncoder to train of X\n",
        "*   AutoEncoder's Encoder part reduces the input features in a such way that the decoder part can reproduce the inputs\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KkPaLUlOv2Db"
      },
      "source": [
        "# Encoder network\n",
        "autoModelEncoder=Sequential()\n",
        "autoModelEncoder.add(Dense(100, input_shape=[vec_size]))\n",
        "autoModelEncoder.add(Dense(50, activation='selu'))\n",
        "autoModelEncoder.add(Dense(10, activation='selu'))\n",
        "# Decoder network\n",
        "autoModelDecoder=Sequential()\n",
        "autoModelDecoder.add(Dense(50,input_shape=[10]))\n",
        "autoModelDecoder.add(Dense(100, activation='selu'))\n",
        "autoModelDecoder.add(Dense(vec_size, activation='selu'))\n",
        "# Stacked autoEncoder\n",
        "autoEncoder = Sequential([autoModelEncoder,autoModelDecoder])\n",
        "autoEncoder.compile('adam',loss='mse')"
      ],
      "execution_count": 130,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KJ_ARc38SAug",
        "outputId": "16b54a8c-4216-4d0d-d629-7344255729f6"
      },
      "source": [
        "autoEncoder.summary()"
      ],
      "execution_count": 131,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential_9\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "sequential_7 (Sequential)    (None, 10)                25660     \n",
            "_________________________________________________________________\n",
            "sequential_8 (Sequential)    (None, 200)               25850     \n",
            "=================================================================\n",
            "Total params: 51,510\n",
            "Trainable params: 51,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PL4kChp0Snnc",
        "outputId": "8d8073ae-c8fa-49f2-ad58-094aa2ee9433"
      },
      "source": [
        "history = autoEncoder.fit(X,X,epochs=3)"
      ],
      "execution_count": 132,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/3\n",
            "13201/13201 [==============================] - 30s 2ms/step - loss: 1.1941e-04\n",
            "Epoch 2/3\n",
            "13201/13201 [==============================] - 27s 2ms/step - loss: 1.1697e-04\n",
            "Epoch 3/3\n",
            "13201/13201 [==============================] - 27s 2ms/step - loss: 1.1259e-04\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R63Py2hhTJPb"
      },
      "source": [
        "codings = autoModelEncoder.predict(X)"
      ],
      "execution_count": 133,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PP939xyaGi4Y"
      },
      "source": [
        "### Clustering"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "itfuu4TRHbmz"
      },
      "source": [
        "# Predict with 100 clusters\n",
        "# For assignment purpose the cluster size is chosen to be 100 and can\n",
        "# can be explored further to find optimum size\n",
        "Kmean = KMeans(n_clusters=100)\n",
        "Kmean.fit(codings)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "t1_vFBhntqJg"
      },
      "source": [
        "# Save the lables in the dataframe\n",
        "df['Prediction'] = Kmean.labels_"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "id": "cUQuEmwuJJ89",
        "outputId": "f62d877b-2bf7-4c9f-f75e-8881a74f2973"
      },
      "source": [
        "df[['TITLE','STORY','Prediction']].head()"
      ],
      "execution_count": 151,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>TITLE</th>\n",
              "      <th>STORY</th>\n",
              "      <th>Prediction</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Fed official says weak data caused by weather,...</td>\n",
              "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Fed's Charles Plosser sees high bar for change...</td>\n",
              "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
              "      <td>11</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>US open: Stocks fall after Fed official hints ...</td>\n",
              "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
              "      <td>39</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Fed risks falling 'behind the curve', Charles ...</td>\n",
              "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
              "      <td>21</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Fed's Plosser: Nasty Weather Has Curbed Job Gr...</td>\n",
              "      <td>ddUyU0VZz0BRneMioxUPQVP6sIxvM</td>\n",
              "      <td>9</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               TITLE  ... Prediction\n",
              "0  Fed official says weak data caused by weather,...  ...         11\n",
              "1  Fed's Charles Plosser sees high bar for change...  ...         11\n",
              "2  US open: Stocks fall after Fed official hints ...  ...         39\n",
              "3  Fed risks falling 'behind the curve', Charles ...  ...         21\n",
              "4  Fed's Plosser: Nasty Weather Has Curbed Job Gr...  ...          9\n",
              "\n",
              "[5 rows x 3 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 151
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JXuDJ7Y-IvVF",
        "outputId": "dfa38bd7-761e-425c-8ed1-6e2ce14106d7"
      },
      "source": [
        "# Check the cluster 0 news articles\n",
        "df[df['Prediction'] == 0][['TITLE','STORY']].value_counts()\n",
        "# As seen the cluster contains various sub clusters of similar articles"
      ],
      "execution_count": 152,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "TITLE                                                                            STORY                        \n",
              "Fingerprint lock in Samsung Galaxy 5 easily defeated by whitehat hackers         dynZ2e-zzuhPqbMOq7Mq3rCo44vyM    2\n",
              "Free coffee at McDonald's amid breakfast war                                     dM-ub8KuIwsrB2MFbfiNkhw0PNvgM    1\n",
              "Freddie Prinze, Jr.: Working with Kiefer Sutherland Made Me Want to Quit Acting  dhLBOkcY7Z2Jr-MoauAW9o5smlJIM    1\n",
              "Free Ben & Jerry's Ice Cream Tomorrow!                                           dNkKiBF-kLRjmeM4B7Hq0v2I_5PPM    1\n",
              "Free Drug Samples for Doctors Might Prove Costly                                 dbSy6LpD5LyNoWM3dUsR9yyWV50_M    1\n",
              "                                                                                                                 ..\n",
              "Nokia names Rajeev Suri as new CEO                                               d0P4azXWamm0lRMJMTmGz5l2BskIM    1\n",
              "Nokia names Rajeev Suri as new CEO and reports sales drop                        d0P4azXWamm0lRMJMTmGz5l2BskIM    1\n",
              "Nokia phone division to be renamed Microsoft Mobile, reveals leaked letter       deMReXPQYO_bp9MHE90VzPO2NGDhM    1\n",
              "Nokia phones to be renamed Microsoft Mobile                                      deMReXPQYO_bp9MHE90VzPO2NGDhM    1\n",
              "#CancelColbert? Beyond Dichotomies                                               d3tlZOYtOQNVM-MzE66PhtVUUU84M    1\n",
              "Length: 6389, dtype: int64"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 152
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "O_Lw5XipXfJy"
      },
      "source": [
        "if exportModels:\n",
        "  # Export processed Text\n",
        "  folder = os.path.join(modelFileSaveLocation,run)\n",
        "  # Create folder if it does not exist\n",
        "  os.makedirs(folder,exist_ok=True)\n",
        "  pickle.dump(Kmean,\n",
        "              open(os.path.join(folder,'newsaggkmeansAutoEncoder.pkl'),'wb'))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "bGpSMM-VrkHv"
      },
      "source": [
        "### Next steps\n",
        "\n",
        "1. As this is a unsupervised problem, metrics can be calculated using Silhoute score to measure the quality of clusters.\n",
        "\n",
        "2. Currently the articles are getting clubbed together but not up to the mark. Hence to improve the algorithm quality below things can be tried\n",
        "> * Trying out different dimensions for doc2vec vector.\n",
        "> * Trying different encoder network configurations\n",
        "> * Trying various KMeans paramaters\n",
        "> * Trying other clustering algorithms like DBSCAN\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xqECFbm8vr8L"
      },
      "source": [
        "!pip freeze > requirements.txt"
      ],
      "execution_count": 153,
      "outputs": []
    }
  ]
}